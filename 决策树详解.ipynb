{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a7716f",
   "metadata": {},
   "source": [
    "# 信息熵的定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c08dcb",
   "metadata": {},
   "source": [
    "假设样本集合D共有N类，第k类样本所占比例为${p_k}$，则D的信息熵为：\n",
    "\n",
    "${H(D)=-\\sum_{k=1}^Np_klog_2p_k}$\n",
    "\n",
    "信息熵描述的是事件在结果出来之前对可能产生的信息量的期望，描述的是<b>不确定性。\n",
    "    \n",
    "信息熵越大，不确定性越大。H(D)的值越小，则表示D的纯度越高。\n",
    "    \n",
    "显然，信息熵针对的是离散的集合下的定义\n",
    "    \n",
    "信息熵的最小值为0，最大值为${log_2N}$\n",
    "    \n",
    "条件熵的定义：\n",
    "    \n",
    "$H(Y|X)=\\sum_iP(X=i)P(Y|X=i)$\n",
    "    \n",
    "    \n",
    "信息增益：\n",
    "    \n",
    "$IG(Y|X)=H(Y)-H(Y|X)$\n",
    "    \n",
    "信息增益是一个统计量，用来描述一个属性区分数据样本的能力。信息增益越大，那么决策树就会越简洁。这里信息增益的程度用信息熵的变化程度来衡量."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce927cc",
   "metadata": {},
   "source": [
    "根据以下信息构建一棵预测是否贷款的决策树。我们可以看到有4个影响因素：职业，年龄，收入和学历。\n",
    "\n",
    "|  职业   | 年龄  | 收入 | 学历 | 是否贷款 |\n",
    "|  ----  | ----  | ----  | ----  | ----  |\n",
    "| 工人  | 36 |5500  | 高中 |否  |\n",
    "| 工人  | 42 |2800  | 初中 |是  |\n",
    "| 白领  | 45 |3300  | 小学 |是  |\n",
    "| 白领  | 25 |10000  | 本科 |是  |\n",
    "| 白领  | 32 |8000  | 硕士 |否  |\n",
    "| 白领  | 28 |13000  | 博士 |是  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb29ed",
   "metadata": {},
   "source": [
    " ## 计算根节点的信息熵\n",
    " \n",
    " 根节点的信息熵即分类标签的信息熵，\"是\"占$\\frac23$,\"否\"占$\\frac13$,\n",
    " \n",
    " 则信息熵：$H(D)=-(\\frac23log_2\\frac23+\\frac13log_2\\frac13)\\approx0.933$\n",
    " \n",
    " ## 计算属性的信息增益\n",
    " \n",
    " ### 职业\n",
    "\n",
    "$H(D|\"职业\")=-(\\frac13(\\frac12log_2\\frac12+\\frac12log_2\\frac12)+\\frac23(\\frac34log_2\\frac34+\\frac14log_2\\frac14))\\approx0.867$\n",
    "\n",
    "IG(D|\"职业\") = H(D) - H(D|\"职业\") = 0.066\n",
    "\n",
    "###  年龄（以35岁为界）\n",
    "\n",
    "$H(D|\"年龄\")=-(\\frac12(\\frac13log_2\\frac13+\\frac23log_2\\frac23)+\\frac12(\\frac13log_2\\frac13+\\frac23log_2\\frac23))\\approx0.933$\n",
    "\n",
    "IG(D|\"年龄\") = H(D) - H(D|\"年龄\") = 0\n",
    "\n",
    "### 收入（以10000为界）\n",
    "\n",
    "$H(D|\"收入\")=-(\\frac13(1log_21+0log_20)+\\frac23(\\frac12log_2\\frac12+\\frac12log_2\\frac12))\\approx0.667$\n",
    "\n",
    "IG(D|\"收入\") = H(D) - H(D|\"收入\") = 0.266\n",
    "\n",
    "### 学历（以高中为界）\n",
    "\n",
    "$H(D|\"学历\")=-(\\frac23(\\frac12log_2\\frac12+\\frac12log_2\\frac12)+\\frac13(0log_20+1log_21))\\approx0.667$\n",
    "\n",
    "IG(D|\"学历\") = H(D) - H(D|\"学历\") = 0.266\n",
    "\n",
    "选择信息增益最大的属性作为划分属性，即选择“收入”作为根节点\n",
    "\n",
    "作为\"是\"大于10000的分支，标签全部为\"是\"，信息熵为0，已经完成该分支的分类。\n",
    "\n",
    "作为\"否\"大于10000的分支，按照相同的方法：\n",
    "\n",
    "信息熵即分类标签的信息熵，\"是\"占$\\frac12$,\"否\"占$\\frac12$,所以$H=1$\n",
    "\n",
    "可以发现，当选择学历（以高中为界）时，当学历在高中及以上时，是否贷款为否；当学历在高中以下时，是否贷款为是。意味着条件熵$H(D|\"学历\")=0$,此时信息增益最大，所以，选择\"学历\"作为子节点，完成决策树的搭建。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571e4be",
   "metadata": {},
   "source": [
    "从以上建立决策树可以发现，类似学历这样的属性，如果不进行“二分”区分，将产生6个分支，每个分支节点仅包含一个样本。这样的决策树不具有泛化能力，无法对新样本进行有效预测。\n",
    "\n",
    "信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，有些决策树算法不以信息增益作为最优划分属性的选择依据，而选择增益率。\n",
    "\n",
    "<b>增益率的定义\n",
    "    \n",
    "$IG_ratio(D,a) = \\frac{IG(D,a)}{IV(a)}$\n",
    "    \n",
    "$IV(a)=-\\sum_{v=1}^V\\frac{|D^v|}{|D|}log_2\\frac{|D^v|}{|D|}$,被称为属性a的“固有值”\n",
    "\n",
    "属性a的取值有${\\{a^1,a^,...a^V\\}}$,其中$D^{v}$表示D中所有在属性a上取值为$a^{v}$的样本集合。\n",
    "    \n",
    "属性a的可能取值数目越多（V越大），IV(a)的值通常会更大。\n",
    "    \n",
    "计算“收入”的信息增益率为例\n",
    "    \n",
    "\"收入\"的取值有两个，大于10000和不大于10000。\n",
    "    \n",
    "$IV(\"收入\") =-(\\frac13log_2\\frac13+\\frac23log_2\\frac23)\\approx0.933$\n",
    "    \n",
    "    \n",
    "$IG_ratio(D,\"收入\")=\\frac{0.266}{0.933}=0.285$\n",
    "    \n",
    "增益率准则对可取值数目较少的属性有所偏好。\n",
    "\n",
    "因此基于增益率的决策树建立方法：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的（而非直接用增益率作为比对标准）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3561fd5",
   "metadata": {},
   "source": [
    "### 决策树的另一划分标准——基尼指数（CART决策树）\n",
    "\n",
    "<b>基尼值的定义\n",
    "    \n",
    "$Gini(D) = 1- \\sum_{k=1}^Np_k^2$\n",
    "    \n",
    "$Gini\\_index(D,a)= \\sum_{v=1}^V\\frac{|D^v|}{|D|}Gini(D^v)$\n",
    "    \n",
    "在侯选属性集合中，选择那个划分后基尼指数最小的属性为最优划分属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d08ced",
   "metadata": {},
   "source": [
    "同样以计算“收入”的基尼指数为例：\n",
    "\n",
    "$Gini\\_index(D,\"收入\") = \\frac13(1-1)+\\frac23(1-(\\frac12)^2-(\\frac12)^2)\\approx0.333$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21fc3e2",
   "metadata": {},
   "source": [
    "### 连续与缺失值\n",
    "\n",
    "- 连续值处理\n",
    "\n",
    "1）提出原因\n",
    "\n",
    "看看我们上面的例子，有些属性取值是离散的，有些是连续的。连续属性的可取值数目不是有限的，所以不能直接根据连续属性的可取值来对节点进行划分。\n",
    "\n",
    "做法——连续属性离散化技术\n",
    "\n",
    "最简单的方法是二分法。\n",
    "\n",
    "提取划分节点的所有可能\n",
    "\n",
    "给定样本集D和连续属性a，假设a在D中出现了n个不同的取值，将这些值从小到大进行排序，记为$\\{a_1,a_2,...a_n\\}$,划分点选取公式为$Ta=\\{\\frac{a^i+a^{i+1}}2,1<=i<=n-1\\}$,(一共有n-1个划分点）\n",
    "\n",
    "选择最佳划分节点\n",
    "\n",
    "拥有n-1个划分节点后，需要选取最佳划分点，则又可以像离散属性那样考察这些划分点。比如说计算信息增益，哪个划分节点得到的信息增益最大就选哪个。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
