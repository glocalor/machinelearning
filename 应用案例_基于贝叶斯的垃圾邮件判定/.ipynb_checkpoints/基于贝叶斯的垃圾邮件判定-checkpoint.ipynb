{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e27e11",
   "metadata": {},
   "source": [
    "# 问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c06fc99",
   "metadata": {},
   "source": [
    "给定一封邮件，判定它是否属于垃圾邮件。用D表示这封邮件，注意D由N个单词组成。我们用y+表示垃圾邮件，y-表示正常邮件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94fb0a2",
   "metadata": {},
   "source": [
    "问题的数学表达为：\n",
    "\n",
    "$P(y+|D) = \\frac{P(y+)*P(D|y+)}{P(D)}$\n",
    "\n",
    "$P(y-|D) = \\frac{P(y-)*P(D|y-)}{P(D)}$\n",
    "\n",
    "$P(y+),P(y-)$表示先验概率，即表示邮件库里面垃圾邮件和正常邮件的比例即可。\n",
    "\n",
    "D里面有N个单词 $d_1,d_2,...,d_n$\n",
    "\n",
    "$P(D|y+)=P(d_1,d_2,...,d_n|y+)$表示垃圾邮件中出现和这封邮件一模一样的概率有多大\n",
    "\n",
    "$P(d_1,d_2,...,d_n|y+)$可以扩展为$P(d_1|y+)P(d_2|d_1,y+)P(d_3|d_1,d_2,y+)...$\n",
    "\n",
    "假设$d_i$和$d_{i-1}$是完全条件无关的(朴素贝叶斯假设特征之间相互独立，互不影响)，\n",
    "\n",
    "扩展可以简化为$P(d_1|y+)P(d_2|y+)P(d_3|y+)...$\n",
    "\n",
    "对于$𝑃(𝑑1|𝑦+)𝑃(𝑑2|𝑦+)𝑃(𝑑3|𝑦+)...$，只需要统计$d_i$个单词在垃圾邮件中出现的频率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4eb76a",
   "metadata": {},
   "source": [
    "# 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b23919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "def textParse(input_string):\n",
    "    listofTokens = re.split(r\"\\W+\",input_string)\n",
    "    return [token.lower() for token in listofTokens if len(listofTokens) > 2]\n",
    "    \n",
    "def createVocablist(doclist):\n",
    "    vocabSet = Set([])\n",
    "    for document in doclist:\n",
    "        vocabSet = vocabSet | set(document)\n",
    "    return list(vocabSet)\n",
    "    \n",
    "def setOfWord2Vec(vocablist,inputSet):\n",
    "    returnVec = [0]*len(vocablist)\n",
    "    for word in inputSet:\n",
    "        if word in vocablist:\n",
    "            returnVec[vocablist.index(word)] = 1\n",
    "    return returnVec\n",
    "    \n",
    "def trainNB(trainSet,trainClass):\n",
    "    numTrainDocs = len(trainSet)\n",
    "    numWords = len(trainSet[0])\n",
    "    p1 = sum(trainClass)/float(numTrainDocs)  #先验概率：垃圾邮件的概率\n",
    "    p0Num = np.ones(numWords)  #不用9初始化，避免因为某个词不存在，导致概率为0，进而导致整个累乘的结果为0\n",
    "    p1Num = np.ones(numWords)  \n",
    "    p0Denom = 2       #拉普拉斯平滑，也就是分母不能用0初始化，通常设置成类别个数，这是是2分类，所以设置为2\n",
    "      = 2\n",
    "    for i in range（numTrainDocs):\n",
    "        if trainClass[i] == 1: 表示垃圾邮件\n",
    "            p1Num += trainSet[i]   \n",
    "            p1Denom += sum(trainSet[i])   #分母对垃圾邮件中出现的单词总数求和\n",
    "        else: 表示正常邮件\n",
    "            p0Num += trainSet[i]   \n",
    "            p0Denom += sum(trainSet[i])   #分母对正常邮件中出现的单词总数求和\n",
    "    \n",
    "    p1Vec = np.log(p1Num/p1Denom)   #这里的概率可能很小，使用np.log将概率值对%%latex化\n",
    "    p0Vec = np.log(p0Num/p0Denom)\n",
    "    return p0Vec，p1Vec,p0Vec,p1\n",
    "   \n",
    "def classifyNB(wordVec,p0Vec，p1Vec,p1Class):\n",
    "    p1 = log(p1Class)+sum(wordVec*p1Vec)#对数化\n",
    "    p0 = log(1-p1Class)+sum(wordVec*p0Vec)#对数化\n",
    "    if p0 > p1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def spam():\n",
    "    doclist = []\n",
    "    classlist = []\n",
    "    for i in range(1,26):\n",
    "        wordlist = textParse(open(f'email/spam/{i}.txt','r',encoding='utf-8').read())\n",
    "        doclist.append(wordlist)\n",
    "        classlist.appenda(1)  # 1表示垃圾邮件\n",
    "        \n",
    "        wordlist = textParse(open(f'email/ham/{i}.txt','r',encoding='utf-8').read())\n",
    "        doclist.append(wordlist)\n",
    "        classlist.appenda(0)  # 1表示垃圾邮件\n",
    "    \n",
    "    vocablist = createVocablist(doclist)\n",
    "    trainSet = list(range(50))\n",
    "    testSet = []\n",
    "    for i in range(10):\n",
    "        randInx = int(random.uniform(0,len(trainSet)))\n",
    "        testSet.append(trainSet[randInx])\n",
    "        del (trainSet[randInx])\n",
    "        \n",
    "    trainMat = []\n",
    "    trainClass = []\n",
    "    for docIndex in trainSet:\n",
    "        trainMat.append(setOfWord2Vec(vocablist,doclist[docIndex]))\n",
    "        trainClass.append(classlist[docIndex])\n",
    "    p0Vec，p1Vec,p1 = trainNB(np.array(trainMat),np.array(trainClass))\n",
    "    errorCount = 0\n",
    "    for docIndex in testSet:\n",
    "        wordVec = setOfWord2Vec(vocablist,doclist[docIndex])\n",
    "        if classifyNB(np.array(wordVec),p0Vec，p1Vec,p1) != classlist[docIndex]:\n",
    "            errorCount ++\n",
    "    print(f\"当前10个测试样本，错了{errorCount}\"个)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    spam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce610440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e464894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "randInx = int(random.uniform(0,50))\n",
    "randInx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4aa4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The competition is so intense that some say they’ve given up on their dreams and aspirations.\\nIn March this year, another Chinese term emerged online. Reflecting an attitude toward life, the term “bai lan” is translated to mean “let it rot.” Posts related to the topic have garnered more than 91 million views on Chinese social media giant Weibo as of Wednesday. \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "open(f'email/spam/{i}.txt','r',encoding='utf-8').read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
