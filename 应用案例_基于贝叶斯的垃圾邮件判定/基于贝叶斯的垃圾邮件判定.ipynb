{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e27e11",
   "metadata": {},
   "source": [
    "# 问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c06fc99",
   "metadata": {},
   "source": [
    "给定一封邮件，判定它是否属于垃圾邮件。用D表示这封邮件，注意D由N个单词组成。我们用y+表示垃圾邮件，y-表示正常邮件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94fb0a2",
   "metadata": {},
   "source": [
    "问题的数学表达为：\n",
    "\n",
    "$P(y+|D) = \\frac{P(y+)*P(D|y+)}{P(D)}$\n",
    "\n",
    "$P(y-|D) = \\frac{P(y-)*P(D|y-)}{P(D)}$\n",
    "\n",
    "$P(y+),P(y-)$表示先验概率，即表示邮件库里面垃圾邮件和正常邮件的比例即可。\n",
    "\n",
    "D里面有N个单词 $d_1,d_2,...,d_n$\n",
    "\n",
    "$P(D|y+)=P(d_1,d_2,...,d_n|y+)$表示垃圾邮件中出现和这封邮件一模一样的概率有多大\n",
    "\n",
    "$P(d_1,d_2,...,d_n|y+)$可以扩展为$P(d_1|y+)P(d_2|d_1,y+)P(d_3|d_1,d_2,y+)...$\n",
    "\n",
    "假设$d_i$和$d_{i-1}$是完全条件无关的(朴素贝叶斯假设特征之间相互独立，互不影响)，\n",
    "\n",
    "扩展可以简化为$P(d_1|y+)P(d_2|y+)P(d_3|y+)...$\n",
    "\n",
    "对于$𝑃(𝑑1|𝑦+)𝑃(𝑑2|𝑦+)𝑃(𝑑3|𝑦+)...$，只需要统计$d_i$个单词在垃圾邮件中出现的频率\n",
    "\n",
    "在程序代码实现时：\n",
    "\n",
    "考虑到仅仅是比较$P(y+|D)$和$P(y-|D)$的大小\n",
    "\n",
    "对概率P的等式两边都套用log，且分母${P(D)}$是常数，不用考虑\n",
    "\n",
    "$logP(y+|D)$等效于$log𝑃(𝑑_1|𝑦+) + log𝑃(𝑑_2|𝑦+)+...+log𝑃(𝑑_n|𝑦+)$\n",
    "\n",
    "$logP(y-|D)$等效于$log𝑃(𝑑_1|𝑦-) + log𝑃(𝑑_2|𝑦-)+...+log𝑃(𝑑_n|𝑦-)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4eb76a",
   "metadata": {},
   "source": [
    "# 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b23919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前10个测试样本，错了0个\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "def textParse(input_string):\n",
    "    listofTokens = re.split(r\"\\W+\",input_string)\n",
    "    return [token.lower() for token in listofTokens if len(listofTokens) > 2]\n",
    "    \n",
    "def createVocablist(doclist):\n",
    "    vocabSet = set([])\n",
    "    for document in doclist:\n",
    "        vocabSet = vocabSet | set(document)\n",
    "    return list(vocabSet)\n",
    "    \n",
    "def setOfWord2Vec(vocablist,inputSet):\n",
    "    returnVec = [0]*len(vocablist)\n",
    "    for word in inputSet:\n",
    "        if word in vocablist:\n",
    "            returnVec[vocablist.index(word)] = 1\n",
    "    return returnVec\n",
    "    \n",
    "def trainNB(trainSet,trainClass):\n",
    "    numTrainDocs = len(trainSet)\n",
    "    numWords = len(trainSet[0])\n",
    "    p1 = sum(trainClass)/float(numTrainDocs)  #先验概率：垃圾邮件的概率\n",
    "    p0Num = np.ones(numWords)  #不用9初始化，避免因为某个词不存在，导致概率为0，进而导致整个累乘的结果为0\n",
    "    p1Num = np.ones(numWords)  \n",
    "    p0Denom = 2       #拉普拉斯平滑，也就是分母不能用0初始化，通常设置成类别个数，这是是2分类，所以设置为2\n",
    "    p1Denom = 2\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainClass[i] == 1:          #表示垃圾邮件\n",
    "            p1Num += trainSet[i]   \n",
    "            p1Denom += sum(trainSet[i])   #分母对垃圾邮件中出现的单词总数求和\n",
    "        else:                           #表示正常邮件\n",
    "            p0Num += trainSet[i]   \n",
    "            p0Denom += sum(trainSet[i])   #分母对正常邮件中出现的单词总数求和\n",
    "    \n",
    "    p1Vec = np.log(p1Num/p1Denom)   #这里的概率可能很小，使用np.log将概率值对%%latex化\n",
    "    p0Vec = np.log(p0Num/p0Denom)\n",
    "    return p0Vec,p1Vec,p1\n",
    "   \n",
    "def classifyNB(wordVec,p0Vec,p1Vec,p1Class):\n",
    "    p1 = np.log(p1Class)+sum(wordVec*p1Vec)#对数化\n",
    "    p0 = np.log(1-p1Class)+sum(wordVec*p0Vec)#对数化\n",
    "    if p0 > p1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def spam():\n",
    "    doclist = []\n",
    "    classlist = []\n",
    "    for i in range(1,26):\n",
    "        wordlist = textParse(open(f'email/spam/{i}.txt','r',encoding='utf-8').read())\n",
    "        doclist.append(wordlist)\n",
    "        classlist.append(1)  # 1表示垃圾邮件\n",
    "        \n",
    "        wordlist = textParse(open(f'email/ham/{i}.txt','r',encoding='utf-8').read())\n",
    "        doclist.append(wordlist)\n",
    "        classlist.append(0)  # 1表示垃圾邮件\n",
    "    \n",
    "    vocablist = createVocablist(doclist)\n",
    "    trainSet = list(range(50))\n",
    "    testSet = []\n",
    "    for i in range(10):\n",
    "        randInx = int(random.uniform(0,len(trainSet)))\n",
    "        testSet.append(trainSet[randInx])\n",
    "        del (trainSet[randInx])\n",
    "        \n",
    "    trainMat = []\n",
    "    trainClass = []\n",
    "    for docIndex in trainSet:\n",
    "        trainMat.append(setOfWord2Vec(vocablist,doclist[docIndex]))\n",
    "        trainClass.append(classlist[docIndex])\n",
    "    p0Vec,p1Vec,p1 = trainNB(np.array(trainMat),np.array(trainClass))\n",
    "    errorCount = 0\n",
    "    for docIndex in testSet:\n",
    "        wordVec = setOfWord2Vec(vocablist,doclist[docIndex])\n",
    "        if classifyNB(np.array(wordVec),p0Vec,p1Vec,p1) != classlist[docIndex]:\n",
    "            errorCount += 1\n",
    "    print(f\"当前10个测试样本，错了{errorCount}个\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    spam()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
